

```
python .venv/lib/python3.8/site-packages/tensorflow/python/tools/saved_model_cli.py show --dir hey_fourth_brain --all
```
Output
```
MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:

signature_def['__saved_model_init_op']:
  The given SavedModel SignatureDef contains the following input(s):
  The given SavedModel SignatureDef contains the following output(s):
    outputs['__saved_model_init_op'] tensor_info:
        dtype: DT_INVALID
        shape: unknown_rank
        name: NoOp
  Method name is: 

signature_def['serving_default']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['input'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 1, 40, 61)
        name: serving_default_input:0
  The given SavedModel SignatureDef contains the following output(s):
    outputs['output'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 4)
        name: PartitionedCall:0
  Method name is: tensorflow/serving/predict

Defined Functions:
  Function Name: '__call__'
        Named Argument #1
          input

  Function Name: 'gen_tensor_dict'
```

Converting to web model
```
(.venv) (base) ➜  onnx_to_tf git:(main) ✗ tensorflowjs_wizard 
Welcome to TensorFlow.js Converter.
? Please provide the path of model file or the directory that contains model files. 
If you are converting TFHub module please provide the URL.  hey_fourth_brain
? What is your input model format? (auto-detected format is marked with *)  Tensorflow Saved Model *
? What is tags for the saved model?  serve
? What is signature name of the model?  signature name: serving_default
? Do you want to compress the model? (this will decrease the model precision.)  No compression (Higher accuracy)
? Please enter shard size (in bytes) of the weight files?  4194304
? Do you want to skip op validation? 
This will allow conversion of unsupported ops, 
you can implement them as custom ops in tfjs-converter.  No
? Do you want to strip debug ops? 
This will improve model execution performance.  Yes
? Do you want to enable Control Flow V2 ops? 
This will improve branch and loop execution performance.  Yes
? Do you want to provide metadata? 
Provide your own metadata in the form: 
metadata_key:path/metadata.json 
Separate multiple metadata by comma.  
? Which directory do you want to save the converted model in?  web_model
converter command generated:
tensorflowjs_converter --control_flow_v2=True --input_format=tf_saved_model --metadata= --saved_model_tags=serve --signature_name=serving_default --strip_debug_ops=True --weight_shard_size_bytes=4194304 hey_fourth_brain web_model

...
File(s) generated by conversion:
Filename                           Size(bytes)
group1-shard1of1.bin                729244
model.json                          28812
Total size:                         758056
```