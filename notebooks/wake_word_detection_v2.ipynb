{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wake_word_detection_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W7G2nK3A_TX"
      },
      "source": [
        "## Architecture & flow diagram - https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frajashekar%2FQPitMq4MPE.png?alt=media&token=9daae34a-0c80-4920-91bc-bd03eb6661be\n",
        "\n",
        "<img src=\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Frajashekar%2FQPitMq4MPE.png?alt=media&token=9daae34a-0c80-4920-91bc-bd03eb6661be\" width=\"2500\" height=\"500\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yCEn3vhnw66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3d4caa-81c1-479a-ec3e-f9591debd780"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jul 20 22:34:01 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcEKUVynoc4H",
        "outputId": "c742db89-b299-4666-8dac-a0d815883446"
      },
      "source": [
        "!cat /proc/meminfo | head -1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MemTotal:       26696424 kB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0PMBzx9oij0",
        "outputId": "e67b1d70-8649-41b1-a17d-2b2e9b59fe90"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3OJDVLlosX2",
        "outputId": "76ef9ab2-f0ba-4e33-d82f-2bbf42d5b178"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/Colab/Fourth.Brain/wake_word_detection/howl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Colab/Fourth.Brain/wake_word_detection/howl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prW558OX5noJ",
        "outputId": "b515583a-08fc-45c3-dfdd-85af589ba556"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IvOcrIf3p38",
        "outputId": "d8c84938-1040-480f-f12e-4aa5b16176dc"
      },
      "source": [
        "# install dependencies\n",
        "# pocketsphinx requires https://github.com/bambocher/pocketsphinx-python#install-requirements\n",
        "!sudo apt-get install -qq python python-dev python-pip build-essential swig git libpulse-dev libasound2-dev\n",
        "# pyaudio\n",
        "!sudo apt-get install python-pyaudio python3-pyaudio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-pyaudio is already the newest version (0.2.11-1build2).\n",
            "python3-pyaudio is already the newest version (0.2.11-1build2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK2iknnb8Iqp"
      },
      "source": [
        "# unrar data\n",
        "!unrar x -o- data.rar /content/ > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSsGr5aWqYcg"
      },
      "source": [
        "# load data train meta data\n",
        "import json\n",
        "from pathlib import Path\n",
        "def read_meta_data(path, jsonl_name):\n",
        "  path = Path(path)\n",
        "  metadata_list = []\n",
        "  with open(path/jsonl_name) as f:\n",
        "      for json_str in iter(f.readline, \"\"):\n",
        "          metadata = json.loads(json_str)\n",
        "          # metadata['path'] = f\"{path}/audio/{metadata['path']}\"\n",
        "          metadata['path'] = (path / \"audio\" /  metadata['path']).absolute()\n",
        "          metadata_list.append(metadata)\n",
        "  return metadata_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVsh-dade8BW"
      },
      "source": [
        "postive_data_path = \"/content/data/hey-fourth-brain-positive/\"\n",
        "train_pos_metadata = read_meta_data(postive_data_path, \"aligned-metadata-training.jsonl\")\n",
        "dev_pos_metadata = read_meta_data(postive_data_path, \"aligned-metadata-dev.jsonl\")\n",
        "test_pos_metadata = read_meta_data(postive_data_path, \"aligned-metadata-test.jsonl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbjXiWLh6Xsd",
        "outputId": "0f90af85-d5d4-4245-f35a-7925d9ec3682"
      },
      "source": [
        "train_pos_metadata[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'end_timestamps': [480.0,\n",
              "  730.0,\n",
              "  730.0,\n",
              "  730.0,\n",
              "  835.0,\n",
              "  940.0,\n",
              "  940.0,\n",
              "  940.0,\n",
              "  1021.25,\n",
              "  1102.5,\n",
              "  1183.75,\n",
              "  1265.0,\n",
              "  1346.25,\n",
              "  1427.5,\n",
              "  1508.75,\n",
              "  1590.0,\n",
              "  1590.0,\n",
              "  1590.0,\n",
              "  1663.3333333333333,\n",
              "  1736.6666666666667,\n",
              "  1810.0,\n",
              "  1810.0,\n",
              "  1810.0,\n",
              "  1900.0,\n",
              "  1990.0,\n",
              "  1990.0,\n",
              "  1990.0,\n",
              "  2075.0,\n",
              "  2160.0,\n",
              "  2245.0,\n",
              "  2330.0,\n",
              "  2330.0,\n",
              "  2330.0,\n",
              "  2580.0,\n",
              "  2580.0,\n",
              "  2580.0,\n",
              "  2625.0,\n",
              "  2670.0,\n",
              "  2670.0,\n",
              "  2670.0,\n",
              "  2776.0,\n",
              "  2882.0,\n",
              "  2988.0,\n",
              "  3094.0,\n",
              "  3200.0,\n",
              "  3200.0,\n",
              "  3200.0,\n",
              "  3350.0,\n",
              "  3500.0,\n",
              "  3650.0,\n",
              "  3650.0,\n",
              "  3770.0,\n",
              "  3838.0,\n",
              "  3906.0,\n",
              "  3974.0,\n",
              "  4042.0,\n",
              "  4110.0,\n",
              "  4110.0,\n",
              "  4110.0,\n",
              "  4235.0,\n",
              "  4360.0,\n",
              "  4485.0,\n",
              "  4610.0,\n",
              "  4610.0,\n",
              "  4610.0,\n",
              "  4890.0,\n",
              "  4890.0,\n",
              "  4890.0,\n",
              "  5015.0,\n",
              "  5140.0,\n",
              "  5265.0,\n",
              "  5390.0,\n",
              "  5515.0,\n",
              "  5640.0],\n",
              " 'path': PosixPath('/content/data/hey-fourth-brain-positive/audio/common_voice_en_20433916.wav'),\n",
              " 'phone_end_timestamps': None,\n",
              " 'phone_strings': None,\n",
              " 'transcription': 'he was decorated with the order of the golden kite fourth class in october',\n",
              " 'word_end_timestamps': None,\n",
              " 'words': None}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xP39bHy2k3s",
        "outputId": "0457fe08-a4e3-43c9-cec7-de7b109ad63f"
      },
      "source": [
        "print(f\"Train samples in positive dataset {len(train_pos_metadata)}\")\n",
        "print(f\"Dev samples in positive dataset {len(dev_pos_metadata)}\")\n",
        "print(f\"Test samples in positive dataset {len(test_pos_metadata)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train samples in positive dataset 828\n",
            "Dev samples in positive dataset 29\n",
            "Test samples in positive dataset 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h4a4aLS3Mzz"
      },
      "source": [
        "negative_data_path = \"/content/data/hey-fourth-brain-negative/\"\n",
        "train_neg_metadata = read_meta_data(negative_data_path, \"aligned-metadata-training.jsonl\")\n",
        "dev_neg_metadata = read_meta_data(negative_data_path, \"aligned-metadata-dev.jsonl\")\n",
        "test_neg_metadata = read_meta_data(negative_data_path, \"aligned-metadata-test.jsonl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xXLPubZ46Ij",
        "outputId": "a08d3fda-9fd4-4a96-9071-ad71f6481055"
      },
      "source": [
        "print(f\"Train samples in negative dataset {len(train_neg_metadata)}\")\n",
        "print(f\"Dev samples in negative dataset {len(dev_neg_metadata)}\")\n",
        "print(f\"Test samples in negative dataset {len(test_neg_metadata)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train samples in negative dataset 11254\n",
            "Dev samples in negative dataset 322\n",
            "Test samples in negative dataset 312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W584PkFT5PY5"
      },
      "source": [
        "stiched_data_path = \"/content/data/hey-fourth-brain-stiched/\"\n",
        "train_stiched_metadata = read_meta_data(stiched_data_path, \"aligned-metadata-training.jsonl\")\n",
        "dev_stiched_metadata = read_meta_data(stiched_data_path, \"aligned-metadata-dev.jsonl\")\n",
        "test_stiched_metadata = read_meta_data(stiched_data_path, \"aligned-metadata-test.jsonl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giLS9D8b5nYf",
        "outputId": "5488084e-784e-463c-861e-d5ca05f74ff8"
      },
      "source": [
        "print(f\"Train samples in stiched dataset {len(train_stiched_metadata)}\")\n",
        "print(f\"Dev samples in stiched dataset {len(dev_stiched_metadata)}\")\n",
        "print(f\"Test samples in stiched dataset {len(test_stiched_metadata)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train samples in stiched dataset 5000\n",
            "Dev samples in stiched dataset 2500\n",
            "Test samples in stiched dataset 2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U1a6G3S-KCj"
      },
      "source": [
        "train_ds = train_pos_metadata + train_neg_metadata + train_stiched_metadata\n",
        "dev_ds = dev_pos_metadata + dev_neg_metadata + dev_stiched_metadata\n",
        "test_ds = test_pos_metadata + test_neg_metadata + test_stiched_metadata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_4foC2B-SwS",
        "outputId": "f1b711e4-6379-444e-9a90-a7a4fa0a44ac"
      },
      "source": [
        "print(f\"Total Train samples {len(train_ds)}\")\n",
        "print(f\"Total Dev samples {len(dev_ds)}\")\n",
        "print(f\"Total test samples {len(test_ds)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Train samples 17082\n",
            "Total Dev samples 2851\n",
            "Total test samples 2831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6Do59dIB5BH"
      },
      "source": [
        "vocab = [\"hey\", \"fourth\", \"brain\"]\n",
        "inference_sequence = [0, 1, 2]\n",
        "vocab_map = dict(zip(vocab, inference_sequence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwAvtZg3BnbU"
      },
      "source": [
        "inference_sequence_str = ''.join(map(str, inference_sequence))\n",
        "def search_vocab(transcription):\n",
        "  exists = False\n",
        "  final = \"\"\n",
        "  for word in transcription.lower().split():\n",
        "    if word in vocab:\n",
        "      final += str(vocab_map[word])\n",
        "    else:\n",
        "      final += str(len(inference_sequence))\n",
        "  \n",
        "  if final == inference_sequence_str:\n",
        "    exists = True\n",
        "  return exists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg0aXtEtEATT"
      },
      "source": [
        "# dev containing vocab\n",
        "dev_pos_ds = list(filter(lambda x: search_vocab(x['transcription']), dev_ds))\n",
        "# dev NOT containing vocab\n",
        "dev_neg_ds = list(filter(lambda x: not search_vocab(x['transcription']), dev_ds))\n",
        "# test containing vocab\n",
        "test_pos_ds = list(filter(lambda x: search_vocab(x['transcription']), test_ds))\n",
        "# test NOT containing vocab\n",
        "test_neg_ds = list(filter(lambda x: not search_vocab(x['transcription']), test_ds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkfLOzYxFM7Y",
        "outputId": "1c2f6cf2-eda1-4cab-f396-238593824486"
      },
      "source": [
        "test_pos_ds[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'end_timestamps': [0.0,\n",
              "  35.0,\n",
              "  70.0,\n",
              "  70.0,\n",
              "  70.0,\n",
              "  140.0,\n",
              "  210.0,\n",
              "  280.0,\n",
              "  349.9999999999998,\n",
              "  419.9999999999998,\n",
              "  419.9999999999998,\n",
              "  419.9999999999998,\n",
              "  524.9999999999998,\n",
              "  629.9999999999998,\n",
              "  734.9999999999998,\n",
              "  839.9999999999998],\n",
              " 'path': PosixPath('/content/data/hey-fourth-brain-stiched/audio/6010.wav'),\n",
              " 'phone_end_timestamps': None,\n",
              " 'phone_strings': None,\n",
              " 'transcription': 'hey fourth brain',\n",
              " 'word_end_timestamps': None,\n",
              " 'words': None}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmyQImAo6fVv"
      },
      "source": [
        "import librosa\n",
        "import warnings\n",
        "\n",
        "def load_audio_data(path: str, sr: int = 16000, mono: bool = True):\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter('ignore')\n",
        "        return librosa.core.load(path, sr=sr, mono=mono)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZW5Y_YjX6Cr"
      },
      "source": [
        "def compute_labels(metadata):\n",
        "        frame_labels = dict()\n",
        "        start_timestamp = []\n",
        "        char_indices = []\n",
        "\n",
        "        char_idx = 0\n",
        "        for word in metadata[\"transcription\"].lower().split():\n",
        "          if word in vocab:\n",
        "            vocab_found = True\n",
        "            word_size = len(word.rstrip())\n",
        "\n",
        "            # if the current word is in vocab, store necessary informations\n",
        "            if vocab_found:\n",
        "                label = vocab_map[word]\n",
        "                end_timestamp = metadata['end_timestamps'][char_idx + word_size - 1]\n",
        "                frame_labels[end_timestamp] = label\n",
        "                char_indices.append((label, list(range(char_idx, char_idx + word_size))))\n",
        "                start_timestamp.append((label, metadata['end_timestamps'][char_idx - 1] if char_idx > 0 else 0.0))\n",
        "\n",
        "            char_idx += word_size + 1  # space\n",
        "\n",
        "        return  {\n",
        "            \"timestamp_label_map\": frame_labels,\n",
        "            \"start_timestamp\": start_timestamp,\n",
        "            \"char_indices\": char_indices\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ektr1tOpMdfR"
      },
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def process_batch(batch):\n",
        "    sample_rate = 16000\n",
        "    window_size_ms = 750\n",
        "    negative_label = len(vocab)\n",
        "    examples = []\n",
        "    max_window_size = 16000\n",
        "    max_length = int(window_size_ms / 1000 * sample_rate)\n",
        "\n",
        "    for sample in batch:\n",
        "      example = {}\n",
        "      example['audio_data'] = torch.from_numpy(load_audio_data(sample['path']))\n",
        "      example['label_data'] = compute_labels(sample)\n",
        "      # if the sample does not contain any sample value\n",
        "      if not example['label_data'][\"timestamp_label_map\"]:\n",
        "        if example['audio_data'].size(-1) < max_length:\n",
        "          examples.append((negative_label, example['audio_data']))\n",
        "        else:\n",
        "          a = random.randint(0, example['audio_data'].size(-1) - max_length)\n",
        "          examples.append((negative_label, example['audio_data'][..., a:a + max_window_size]))\n",
        "        continue\n",
        "      \n",
        "      end_ms, label = random.choice(list( example['label_data'][\"timestamp_label_map\"].items()))\n",
        "      end_ms_rand = end_ms + (random.random() * 20)\n",
        "      b = int((end_ms_rand / 1000) * sample_rate)\n",
        "      a = max(b - int((window_size_ms / 1000) * sample_rate), 0)\n",
        "      examples.append((label, example['audio_data'][..., a:b])) \n",
        "    \n",
        "    labels_lst = [x[0] for x in examples]\n",
        "    audio_ds = [x[1] for x in examples]\n",
        "    lengths=[x[1].size(-1) for x in examples]\n",
        "\n",
        "    lengths_nd = np.array(lengths)\n",
        "    sort_indices = np.argsort(-lengths_nd)\n",
        "    audio_data_lst = np.array(audio_ds, dtype=object)[sort_indices].tolist()\n",
        "    labels_lst = np.array(labels_lst, dtype=object)[sort_indices].tolist()\n",
        "    lengths = np.array(lengths, dtype=object)[sort_indices].tolist()\n",
        "    \n",
        "    audio_tensor = []\n",
        "    for audio_data in audio_data_lst:\n",
        "      if audio_data.size(-1) > max_length:\n",
        "        audio_data = audio_data[:max_length]\n",
        "      squeezed_data = audio_data.squeeze()\n",
        "      if squeezed_data.dim() == 0:\n",
        "          squeezed_data = squeezed_data.unsqueeze(0)\n",
        "      if random.random() < 0.5:\n",
        "          x = (torch.zeros(max_length - audio_data.size(-1)), squeezed_data)\n",
        "      else:\n",
        "          x = (squeezed_data, torch.zeros(max_length - audio_data.size(-1)))\n",
        "      audio_tensor.append(torch.cat(x, -1)) \n",
        "\n",
        "\n",
        "    batch_tensor = {\n",
        "      'audio_data' : torch.stack(audio_tensor),\n",
        "      'labels' : torch.tensor(labels_lst),\n",
        "      'lengths' : torch.tensor(lengths)\n",
        "    }\n",
        "\n",
        "    return batch_tensor\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4IaCOOJIlr7"
      },
      "source": [
        "import torch.utils.data as tud\n",
        "\n",
        "batch_size = 16\n",
        "num_workers = 0\n",
        "\n",
        "train_dl = tud.DataLoader(train_ds,\n",
        "                  batch_size=batch_size,\n",
        "                  drop_last=True,\n",
        "                  shuffle=True,\n",
        "                  num_workers=num_workers,\n",
        "                  collate_fn=process_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhxIOFa_6UxL",
        "outputId": "47f1b2f7-9090-4375-8121-ce7c5af349cf"
      },
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Inference on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Inference on GPU ...')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Inference on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpjtBJxE7BON"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_labels, num_maps1, num_maps2, num_hidden_input, hidden_size):\n",
        "        super(CNN, self).__init__()\n",
        "        conv0 = nn.Conv2d(1, num_maps1, (8, 16), padding=(4, 0), stride=(2, 2), bias=True)\n",
        "        pool = nn.MaxPool2d(2)\n",
        "        conv1 = nn.Conv2d(num_maps1, num_maps2, (5, 5), padding=2, stride=(2, 1), bias=True)\n",
        "        self.encoder1 = nn.Sequential(conv0,\n",
        "                                      nn.ReLU(),\n",
        "                                      pool,\n",
        "                                      nn.BatchNorm2d(num_maps1, affine=True))\n",
        "        self.encoder2 = nn.Sequential(conv1,\n",
        "                                      nn.ReLU(),\n",
        "                                      pool,\n",
        "                                      nn.BatchNorm2d(num_maps2, affine=True))\n",
        "        self.output = nn.Sequential(nn.Linear(num_hidden_input, hidden_size),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Dropout(0.1),\n",
        "                                    nn.Linear(hidden_size, num_labels))\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        x = x[:, :1]  # log-Mels only\n",
        "        x = x.permute(0, 1, 3, 2)  # (time, frequency)\n",
        "        x1 = self.encoder1(x)\n",
        "        x2 = self.encoder2(x1)\n",
        "        x2 = x2.view(x2.size(0), x2.size(1), -1)\n",
        "        x = x2.view(x2.size(0), -1)\n",
        "        return self.output(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM3DrQRL8Vu6"
      },
      "source": [
        "num_labels = len(vocab) + 1 # oov\n",
        "num_maps1  = 48\n",
        "num_maps2  = 64\n",
        "num_hidden_input =  768\n",
        "hidden_size = 128\n",
        "model = CNN(num_labels, num_maps1, num_maps2, num_hidden_input, hidden_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZ-9Vwu29TDZ",
        "outputId": "8b1524e2-e122-41fe-e96a-f441d3ab7a22"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (encoder1): Sequential(\n",
              "    (0): Conv2d(1, 48, kernel_size=(8, 16), stride=(2, 2), padding=(4, 0))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (encoder2): Sequential(\n",
              "    (0): Conv2d(48, 64, kernel_size=(5, 5), stride=(2, 1), padding=(2, 2))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (output): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.1, inplace=False)\n",
              "    (3): Linear(in_features=128, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wcjJi_tnPqR"
      },
      "source": [
        "from torch.optim.adamw import AdamW\n",
        "\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.0\n",
        "lr_decay = 0.75\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "params = list(filter(lambda x: x.requires_grad, model.parameters()))\n",
        "optimizer = AdamW(params, learning_rate, weight_decay=weight_decay)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IvUgSfwsxir",
        "outputId": "b26bb7d8-a844-4f75-af90-7228a61b78ec"
      },
      "source": [
        "pip install torchaudio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchaudio) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o09N8h23Q-65",
        "outputId": "2cef21f5-0e24-420a-b213-a43df3d3c9ae"
      },
      "source": [
        "from torchaudio.transforms import MelSpectrogram, ComputeDeltas\n",
        "\n",
        "epochs = 2\n",
        "num_mels = 40 # https://en.wikipedia.org/wiki/Mel_scale\n",
        "num_fft = 512 # window length - Fast Fourier Transform\n",
        "hop_length = 200 \n",
        "sample_rate = 16000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  total_loss = torch.Tensor([0.0]).to(device)\n",
        "\n",
        "  for batch in train_dl:\n",
        "    audio_data = batch['audio_data'].to(device)\n",
        "    labels = batch['labels'].to(device)\n",
        "    lengths = batch['lengths'].to(device)\n",
        "\n",
        "    # Transformations\n",
        "    # Mel-scale spectrogram is a combination of Spectrogram and mel scale conversion\n",
        "    mel_spectrogram  = MelSpectrogram(n_mels=num_mels,\n",
        "                                      sample_rate=sample_rate,\n",
        "                                      n_fft=num_fft,\n",
        "                                      hop_length=hop_length)\n",
        "    mel_spectrogram.to(device)\n",
        "    log_mels = mel_spectrogram(audio_data).add_(1e-7).log_().contiguous()\n",
        "\n",
        "    # Compute delta coefficients of a tensor, usually a spectrogram.\n",
        "    compute_deltas = ComputeDeltas()\n",
        "    deltas = compute_deltas(log_mels)\n",
        "    accels = compute_deltas(deltas)\n",
        "\n",
        "    mel_audio_data = torch.stack((log_mels, deltas, accels), 1).to(device)\n",
        "    lengths = ((lengths - num_fft) // hop_length + 1).long()\n",
        "\n",
        "    # Train\n",
        "    predicted_scores = model(mel_audio_data, lengths)\n",
        "    # get loss\n",
        "    loss = criterion(predicted_scores, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    model.zero_grad()\n",
        "\n",
        "    # backward propagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        total_loss += loss\n",
        "      \n",
        "  for group in optimizer.param_groups:\n",
        "    group[\"lr\"] *= lr_decay\n",
        "\n",
        "  mean = total_loss / len(train_dl)\n",
        "  print(f\"Epoch {epoch}: Training loss {mean.item()} with lr {group['lr']}\")\n",
        "  \n",
        "  # Evaluate  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: Training loss 0.2580280005931854 with lr 0.00075\n",
            "Epoch 1: Training loss 0.1621510088443756 with lr 0.0005625000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dWI1jkNV4pl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}